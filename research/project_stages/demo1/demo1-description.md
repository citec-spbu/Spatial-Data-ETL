### Первый вариант разработки прототипа:

Загрузка данных с помощью osmnx: тк команда лучше ознакомилась с этим инструментом. 	Он показался нам удобным.

В ETL процессе 3 этапа:
1. Сбор всех данных по указанной территории 
2. Обработка - в нашем случае, фильтрация нужных типов объектов и тегов по проценту их заполняемости в OSM - оставлять те, которые заполнены у 90% объектов.
3. Загрузка в БД.	
Между этапами данные передаются в .сsv файлах.

Схема разработки по выше описанному сценарию в файле demo1-scheme-tasks.pdf
Там же выделены зоны ответственности членов команды и описаны соответствующие задачи.


### Обратная связь кураторов проекта:
	
1. Обратили внимание на то, что мы должны иметь возможность решать различные задачи на собранных данных. Возникновение новой аналитической задачи может потребовать подготовки нового набора данных, но **не должно приводить к повторной загрузке данных** из первоисточника.
   
В нашем сценарии загрузка и обработка(подготовка нужных данных) **происходят строго последовательно** - требование (1) не выполняется.

2. Требование (1) мотивирует к следованию стратегии ELT, а не ETL. 

4. Рекомендовано внимательнее рассмотреть способы обработки и преобразования pbf файлов. В случае перехода к ELT обработка данных возможна именно этими методами.
	